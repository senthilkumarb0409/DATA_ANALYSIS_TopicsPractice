{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29471422-0455-4b01-b8f6-03eaa3135fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "def load_dataset(file_path):\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "        print(\"\\nDataset loaded successfully!\")\n",
    "        return df\n",
    "    except FileNotFoundError:\n",
    "        print(\"File not found. Please check the file path.\")\n",
    "        return None\n",
    "\n",
    "def explore_dataset(df):\n",
    "    print(\"\\nFirst 5 rows of the dataset:\")\n",
    "    print(df.head())\n",
    "    print(\"\\nDataset Info:\")\n",
    "    print(df.info())\n",
    "    print(\"\\nSummary Statistics:\")\n",
    "    print(df.describe(include='all'))\n",
    "    print(\"\\nMissing Values:\")\n",
    "    print(df.isnull().sum())\n",
    "    print(\"\\nDuplicate Rows:\")\n",
    "    print(df.duplicated().sum())\n",
    "\n",
    "def validate_data(df):\n",
    "    print(\"\\nRunning basic data validation checks...\")\n",
    "    issues = []\n",
    "\n",
    "    if 'AGE' in df.columns and pd.api.types.is_numeric_dtype(df['AGE']):\n",
    "        try:\n",
    "            if (df['AGE'] < 0).any():\n",
    "                issues.append(\"AGE column contains negative values.\")\n",
    "        except TypeError:\n",
    "            issues.append(\"AGE column contains non-numeric or incompatible values.\")\n",
    "\n",
    "    if 'ID' in df.columns:\n",
    "        if df['ID'].duplicated().any():\n",
    "            issues.append(\"ID column contains duplicate values.\")\n",
    "\n",
    "    null_counts = df.isnull().sum()\n",
    "    if null_counts.any():\n",
    "        issues.append(\"Some columns still have missing values:\")\n",
    "        issues.append(str(null_counts[null_counts > 0]))\n",
    "\n",
    "    if issues:\n",
    "        print(\"\\nValidation Issues Found:\")\n",
    "        for issue in issues:\n",
    "            print(\"-\", issue)\n",
    "    else:\n",
    "        print(\"\\nNo data validation issues found.\")\n",
    "\n",
    "def clean_dataset(df):\n",
    "    df.columns = df.columns.str.upper()\n",
    "    df = df.drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "    date_cols = [col for col in df.columns if 'date' in col.lower() or 'time' in col.lower()]\n",
    "    df['__row_state__'] = 'valid'\n",
    "\n",
    "    for col in df.select_dtypes(include='object').columns:\n",
    "        df[col] = df[col].astype(str).str.strip().str.lower().str.title()\n",
    "\n",
    "    if 'ITEM' in df.columns:\n",
    "        df['ITEM'] = df['ITEM'].replace(['Unknown', 'Error', '', 'Nan'], 'Other')\n",
    "\n",
    "    for col in ['PAYMENT METHOD', 'LOCATION']:\n",
    "        if col in df.columns:\n",
    "            df[col] = df[col].replace(['Unknown', 'Error', '', 'Nan'], 'Other')\n",
    "\n",
    "    if {'PRICE', 'QUANTITY', 'TOTAL SPENT'}.issubset(df.columns):\n",
    "        df['PRICE'] = pd.to_numeric(df['PRICE'], errors='coerce')\n",
    "        df['QUANTITY'] = pd.to_numeric(df['QUANTITY'], errors='coerce')\n",
    "        df['TOTAL SPENT'] = pd.to_numeric(df['TOTAL SPENT'], errors='coerce')\n",
    "\n",
    "        for idx, row in df.iterrows():\n",
    "            p = row['PRICE']\n",
    "            q = row['QUANTITY']\n",
    "            t = row['TOTAL SPENT']\n",
    "\n",
    "            known = [pd.notna(p), pd.notna(q), pd.notna(t)]\n",
    "\n",
    "            if known.count(True) == 2:\n",
    "                if pd.isna(p):  # Calculate PRICE if missing\n",
    "                    if q != 0:\n",
    "                        df.at[idx, 'PRICE'] = t / q\n",
    "                    else:\n",
    "                        df.at[idx, 'PRICE'] = 0\n",
    "                elif pd.isna(q):  # Calculate QUANTITY if missing\n",
    "                    if p != 0:\n",
    "                        df.at[idx, 'QUANTITY'] = t / p\n",
    "                    else:\n",
    "                        df.at[idx, 'QUANTITY'] = 0\n",
    "                elif pd.isna(t):  # Calculate TOTAL SPENT if missing\n",
    "                    df.at[idx, 'TOTAL SPENT'] = p * q\n",
    "            elif known.count(True) < 2:  # Set values to 0 if two or more columns are missing\n",
    "                if pd.isna(p):\n",
    "                    df.at[idx, 'PRICE'] = 0\n",
    "                if pd.isna(q):\n",
    "                    df.at[idx, 'QUANTITY'] = 0\n",
    "                if pd.isna(t):\n",
    "                    df.at[idx, 'TOTAL SPENT'] = 0\n",
    "\n",
    "    for col in df.select_dtypes(include='object').columns:\n",
    "        if col not in date_cols:\n",
    "            df[col] = df[col].replace(['Unknown', 'Error', '', 'Nan'], 'Unknown')\n",
    "            df[col] = df[col].fillna('Unknown')\n",
    "\n",
    "    for col in df.select_dtypes(include=['float64', 'int64']).columns:\n",
    "        df[col] = df[col].fillna(df[col].median())\n",
    "\n",
    "    df = df.loc[:, df.isnull().mean() < 0.5]\n",
    "\n",
    "    if 'AGE' in df.columns:\n",
    "        df['AGE'] = df['AGE'].round().astype('Int64')\n",
    "\n",
    "    for col in date_cols:\n",
    "        df[col] = pd.to_datetime(df[col], errors='coerce', format='%Y-%m-%d')\n",
    "        missing_date_mask = df[col].isnull()\n",
    "        df.loc[missing_date_mask, '__row_state__'] = 'missing_date'\n",
    "        df[col] = df[col].fillna(pd.to_datetime('2020-01-01'))\n",
    "\n",
    "    non_date_cols = [col for col in df.columns if col not in date_cols + ['__row_state__']]\n",
    "    unknown_mask = df[non_date_cols].isin(['Unknown']).any(axis=1)\n",
    "    missing_mask = df[non_date_cols].isnull().any(axis=1)\n",
    "    df.loc[unknown_mask | missing_mask, '__row_state__'] = 'replaced_unknown'\n",
    "\n",
    "    df = df.drop(columns=['__row_state__'], errors='ignore')\n",
    "\n",
    "    print(\"\\nCleaned Data Summary:\")\n",
    "    print(\"Columns after cleaning:\", df.columns.tolist())\n",
    "    print(\"Shape after cleaning:\", df.shape)\n",
    "\n",
    "    return df\n",
    "\n",
    "def suggest_data_types(df):\n",
    "    print(\"\\nColumn Type Suggestions:\")\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == 'object' and df[col].nunique() / len(df) < 0.5:\n",
    "            print(f\"- Consider converting '{col}' to 'category'\")\n",
    "        elif pd.api.types.is_float_dtype(df[col]) and (df[col] % 1 == 0).all():\n",
    "            print(f\"- Consider converting '{col}' to 'int'\")\n",
    "\n",
    "def show_high_correlations(df, threshold=0.8):\n",
    "    print(\"\\nHighly Correlated Numerical Features:\")\n",
    "    corr = df.select_dtypes(include=[np.number]).corr()\n",
    "    high_corr = corr.where(np.triu(np.ones(corr.shape), k=1).astype(bool))\n",
    "    result = high_corr.stack().reset_index()\n",
    "    result.columns = ['Feature1', 'Feature2', 'Correlation']\n",
    "    strong = result[abs(result['Correlation']) > threshold]\n",
    "    print(strong if not strong.empty else \"No strong correlations found.\")\n",
    "\n",
    "def detect_outliers(df):\n",
    "    print(\"\\nOutlier Detection:\")\n",
    "    numeric_cols = df.select_dtypes(include=[np.number])\n",
    "    for col in numeric_cols.columns:\n",
    "        Q1 = numeric_cols[col].quantile(0.25)\n",
    "        Q3 = numeric_cols[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        outliers = ((numeric_cols[col] < (Q1 - 1.5 * IQR)) | (numeric_cols[col] > (Q3 + 1.5 * IQR))).sum()\n",
    "        print(f\"- {col}: {outliers} outliers\")\n",
    "\n",
    "def check_duplicate_columns(df):\n",
    "    print(\"\\nChecking for duplicate columns...\")\n",
    "    duplicates = df.T[df.T.duplicated()].T\n",
    "    if not duplicates.empty:\n",
    "        print(f\"Duplicate columns found: {list(duplicates.columns)}\")\n",
    "    else:\n",
    "        print(\"No duplicate columns found.\")\n",
    "\n",
    "def save_cleaned_dataset(df, output_file):\n",
    "    try:\n",
    "        df.to_csv(output_file, index=False)\n",
    "        print(f\"\\nCleaned dataset saved as '{output_file}'\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to save file: {e}\")\n",
    "\n",
    "def generate_cleaning_report(df, output_path=\"cleaning_report.txt\"):\n",
    "    try:\n",
    "        with open(output_path, 'w') as report:\n",
    "            report.write(\"DATA CLEANING REPORT\\n\")\n",
    "            report.write(\"====================\\n\\n\")\n",
    "            report.write(f\"Report Date: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\\n\")\n",
    "            report.write(f\"Final Shape: {df.shape}\\n\")\n",
    "            report.write(\"\\nColumns:\\n\")\n",
    "            for col in df.columns:\n",
    "                report.write(f\"- {col} ({df[col].dtype})\\n\")\n",
    "            report.write(\"\\nNotes:\\n\")\n",
    "            report.write(\"- Duplicates removed.\\n\")\n",
    "            report.write(\"- Column names standardized.\\n\")\n",
    "            report.write(\"- Categorical text cleaned and errors normalized.\\n\")\n",
    "            report.write(\"- Missing values handled (mode/median/default date used).\\n\")\n",
    "            report.write(\"- Highly missing columns dropped (>50%).\\n\")\n",
    "            report.write(\"- Row order preserved.\\n\")\n",
    "        print(f\"Cleaning report saved to '{output_path}'\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to write cleaning report: {e}\")\n",
    "\n",
    "# Sample usage\n",
    "if __name__ == \"__main__\":\n",
    "    file_path = input(\"Enter the path to your CSV file: \")\n",
    "    df = load_dataset(file_path)\n",
    "\n",
    "    if df is not None:\n",
    "        explore_dataset(df)\n",
    "        df = clean_dataset(df)\n",
    "        validate_data(df)\n",
    "        suggest_data_types(df)\n",
    "        show_high_correlations(df)\n",
    "        detect_outliers(df)\n",
    "        check_duplicate_columns(df)\n",
    "        output_file_name = input(\"Enter the output file name for the cleaned dataset (e.g. cleaned_data.csv): \")\n",
    "        save_cleaned_dataset(df, output_file_name)\n",
    "        generate_cleaning_report(df)\n",
    "        print(\"\\nData cleaning and preparation completed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "202522c7-072c-43f8-9119-705e2118c15f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the path to your CSV file:  clean_cafe_sales.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset loaded successfully!\n",
      "\n",
      "Handling missing values for QUANTITY, PRICE PER UNIT, and TOTAL SPENT...\n",
      "Column names in the dataset: Index(['TRANSACTION ID', 'ITEM', 'QUANTITY', 'PRICE PER UNIT', 'TOTAL SPENT',\n",
      "       'PAYMENT METHOD', 'LOCATION', 'TRANSACTION DATE'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the output file name for the cleaned dataset (e.g. final_cleaned_data.csv):  final_clean_cafe_sales.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cleaned dataset saved as 'final_clean_cafe_sales.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def handle_missing_values(df):\n",
    "    print(\"\\nHandling missing values for QUANTITY, PRICE PER UNIT, and TOTAL SPENT...\")\n",
    "\n",
    "    # Ensure column names are cleaned from any leading or trailing spaces\n",
    "    df.columns = df.columns.str.strip()\n",
    "\n",
    "    # Check column names\n",
    "    print(\"Column names in the dataset:\", df.columns)\n",
    "\n",
    "    # Iterate through rows to handle missing values\n",
    "    for idx, row in df.iterrows():\n",
    "        # Get the values for QUANTITY, PRICE PER UNIT, and TOTAL SPENT\n",
    "        quantity = row['QUANTITY']\n",
    "        price_per_unit = row['PRICE PER UNIT']\n",
    "        total_spent = row['TOTAL SPENT']\n",
    "        \n",
    "        # Convert to numeric where possible, invalid parsing will result in NaN\n",
    "        try:\n",
    "            quantity = pd.to_numeric(quantity, errors='coerce')\n",
    "            price_per_unit = pd.to_numeric(price_per_unit, errors='coerce')\n",
    "            total_spent = pd.to_numeric(total_spent, errors='coerce')\n",
    "        except ValueError:\n",
    "            continue  # If there's a value error, we just skip that row (though it should not occur with 'coerce')\n",
    "\n",
    "        # Check for \"Unknown\" values\n",
    "        missing_values = 0\n",
    "        if row['QUANTITY'] == \"Unknown\":\n",
    "            missing_values += 1\n",
    "        if row['PRICE PER UNIT'] == \"Unknown\":\n",
    "            missing_values += 1\n",
    "        if row['TOTAL SPENT'] == \"Unknown\":\n",
    "            missing_values += 1\n",
    "\n",
    "        # If only one value is missing, calculate it based on the other two\n",
    "        if missing_values == 1:\n",
    "            if row['QUANTITY'] == \"Unknown\" and price_per_unit != \"Unknown\" and total_spent != \"Unknown\":\n",
    "                df.at[idx, 'QUANTITY'] = total_spent / price_per_unit\n",
    "            elif row['PRICE PER UNIT'] == \"Unknown\" and quantity != \"Unknown\" and total_spent != \"Unknown\":\n",
    "                df.at[idx, 'PRICE PER UNIT'] = total_spent / quantity\n",
    "            elif row['TOTAL SPENT'] == \"Unknown\" and quantity != \"Unknown\" and price_per_unit != \"Unknown\":\n",
    "                df.at[idx, 'TOTAL SPENT'] = price_per_unit * quantity\n",
    "        \n",
    "        # If more than one value is missing, set them to 0\n",
    "        elif missing_values > 1:\n",
    "            df.at[idx, 'QUANTITY'] = 0\n",
    "            df.at[idx, 'PRICE PER UNIT'] = 0\n",
    "            df.at[idx, 'TOTAL SPENT'] = 0\n",
    "        \n",
    "        # Convert the values in the relevant columns to whole numbers (integers)\n",
    "        df.at[idx, 'QUANTITY'] = int(float(df.at[idx, 'QUANTITY'])) if pd.notna(df.at[idx, 'QUANTITY']) else 0\n",
    "        df.at[idx, 'PRICE PER UNIT'] = int(float(df.at[idx, 'PRICE PER UNIT'])) if pd.notna(df.at[idx, 'PRICE PER UNIT']) else 0\n",
    "        df.at[idx, 'TOTAL SPENT'] = int(float(df.at[idx, 'TOTAL SPENT'])) if pd.notna(df.at[idx, 'TOTAL SPENT']) else 0\n",
    "\n",
    "    return df\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Get the input file path from the user\n",
    "    input_file_path = input(\"Enter the path to your CSV file: \")\n",
    "\n",
    "    # Load the dataset\n",
    "    try:\n",
    "        df = pd.read_csv(input_file_path)\n",
    "        print(\"\\nDataset loaded successfully!\")\n",
    "        \n",
    "        # Clean column names\n",
    "        df.columns = df.columns.str.strip()\n",
    "\n",
    "        # Handle missing values\n",
    "        df = handle_missing_values(df)\n",
    "        \n",
    "        # Save the cleaned dataset\n",
    "        output_file_name = input(\"Enter the output file name for the cleaned dataset (e.g. final_cleaned_data.csv): \")\n",
    "        df.to_csv(output_file_name, index=False)\n",
    "        print(f\"\\nCleaned dataset saved as '{output_file_name}'\")\n",
    "    \n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: The file at '{input_file_path}' was not found.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
